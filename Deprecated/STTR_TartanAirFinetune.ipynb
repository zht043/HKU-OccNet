{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e1516fd-9365-490b-a939-33e3d31cffc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from torchsummary import summary\n",
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07fecfde-f332-4b9c-9a19-5a1f3264add6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_path = '/workspace/stereo-transformer'\n",
    "pretrained_weight_path = '../../PretrainedWeights/kitti_finetuned_model.pth.tar'\n",
    "sys.path.append(repo_path) # add relative path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f1df86c-5443-4b46-b1ab-0cb639381d88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipyvolume as ipv\n",
    "from module.sttr import STTR\n",
    "from dataset.preprocess import normalization, compute_left_occ_region\n",
    "from utilities.misc import NestedTensor\n",
    "\n",
    "def visualize_3D_points_in_jupyter(points_3D, size=2, marker=\"sphere\"):\n",
    "    # Assuming points_3D is a N x 3 numpy array\n",
    "    x = points_3D[:, 0]\n",
    "    y = points_3D[:, 1]\n",
    "    z = points_3D[:, 2]\n",
    "\n",
    "    ipv.quickscatter(x, y, z, size=size, marker=marker)\n",
    "    ipv.show()\n",
    "\n",
    "from module.sttr import STTR\n",
    "from dataset.preprocess import normalization, compute_left_occ_region\n",
    "from utilities.misc import NestedTensor\n",
    "\n",
    "def load_STTR_model(repo_path, pretrained_weight_path):\n",
    "    # Default parameters\n",
    "    args = type('', (), {})() # create empty args\n",
    "    args.channel_dim = 128\n",
    "    args.position_encoding='sine1d_rel'\n",
    "    args.num_attn_layers=6\n",
    "    args.nheads=8\n",
    "    args.regression_head='ot'\n",
    "    args.context_adjustment_layer='cal'\n",
    "    args.cal_num_blocks=8\n",
    "    args.cal_feat_dim=16\n",
    "    args.cal_expansion_ratio=4\n",
    "\n",
    "\n",
    "    model = STTR(args).cuda().eval()\n",
    "\n",
    "    # Load the pretrained model\n",
    "    model_file_name = pretrained_weight_path\n",
    "    checkpoint = torch.load(model_file_name)\n",
    "    pretrained_dict = checkpoint['state_dict']\n",
    "    model.load_state_dict(pretrained_dict, strict=False) # prevent BN parameters from breaking the model loading\n",
    "    print(\"Pre-trained model successfully loaded.\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def STTR_input_factory(left_img, right_img):\n",
    "    # donwsample attention by stride of 3\n",
    "    left = left_img\n",
    "    right = right_img\n",
    "    h, w, _ = left.shape\n",
    "    bs = 1\n",
    "    \n",
    "    downsample = 3\n",
    "    col_offset = int(downsample / 2)\n",
    "    row_offset = int(downsample / 2)\n",
    "    sampled_cols = torch.arange(col_offset, w, downsample)[None,].expand(bs, -1).cuda()\n",
    "    sampled_rows = torch.arange(row_offset, h, downsample)[None,].expand(bs, -1).cuda()\n",
    "\n",
    "    input_data = {'left': left, 'right':right}\n",
    "    input_data = normalization(**input_data)\n",
    "\n",
    "    # build NestedTensor\n",
    "    input_data = NestedTensor(input_data['left'].cuda()[None,],input_data['right'].cuda()[None,], sampled_cols=sampled_cols, sampled_rows=sampled_rows)\n",
    "    return input_data\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "def disparity_to_3D_points(left_prj, right_prj, disparity):\n",
    "    \"\"\"\n",
    "    Convert disparity map to 3D points using the given projection matrices.\n",
    "\n",
    "    Parameters:\n",
    "    - left_prj: 3x4 numpy array representing the left rectified projection matrix.\n",
    "    - right_prj: 3x4 numpy array representing the right rectified projection matrix.\n",
    "    - disparity: 2D numpy array representing the disparity map.\n",
    "\n",
    "    Returns:\n",
    "    - 3D numpy array with shape (H, W, 3) representing the 3D points.\n",
    "    \"\"\"\n",
    "    # Compute Q matrix from projection matrices\n",
    "    f = left_prj[0, 0]  # Focal length, assuming it's the same for both cameras after rectification\n",
    "    T = right_prj[0, 3] / f  # Baseline\n",
    "\n",
    "    Q = np.array([\n",
    "        [1, 0, 0, -0.5 * disparity.shape[1]],\n",
    "        [0, -1, 0, 0.5 * disparity.shape[0]],\n",
    "        [0, 0, 0, -f],\n",
    "        [0, 0, -1 / T, 0]\n",
    "    ])\n",
    "\n",
    "    # Reproject image to 3D\n",
    "    points_3D = cv2.reprojectImageTo3D(disparity, Q)\n",
    "    return points_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f612b7f-132e-480c-a23b-8069891ab1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained model successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "model = load_STTR_model(repo_path, pretrained_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6d2084-b080-4453-941d-52fb8559c6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89418757-bf99-497f-9b62-0877b9318907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f8348-5cbc-4290-a5c3-e048378dedd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf576bf4-5d7f-45d0-9b37-c137b944f84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6799acb2-261b-4637-af93-d9d2a0ce7b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd86295-edb8-4765-8ad3-a29348aba5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffd7de7e-dacd-443c-a8bf-617be2802135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def load_images_from_directory(directory_path):\n",
    "    # Get all files from the directory\n",
    "    all_files = os.listdir(directory_path)\n",
    "    \n",
    "    # Filter out non-image files if necessary (optional)\n",
    "    image_files = [f for f in all_files if f.endswith('.png') or f.endswith('.jpg') or f.endswith('.jpeg')]\n",
    "    \n",
    "    # Read images and append to a list\n",
    "    images = [cv2.imread(os.path.join(directory_path, image_file)) for image_file in image_files]\n",
    "    \n",
    "    # Convert list of images to numpy array\n",
    "    return np.array(images)\n",
    "\n",
    "def load_depth_data_from_directory(directory_path):\n",
    "    # Get all .npy files from the directory\n",
    "    npy_files = [f for f in os.listdir(directory_path) if f.endswith('.npy')]\n",
    "    \n",
    "    # Load each .npy file and append to a list\n",
    "    depth_data_list = [np.load(os.path.join(directory_path, npy_file)) for npy_file in npy_files]\n",
    "    \n",
    "    return np.array(depth_data_list)\n",
    "\n",
    "class TartanData:\n",
    "    def __init__(self, repo_path, scene_name, part_id, difficulty='Easy'):\n",
    "        self.fx = 320.0  # focal length x\n",
    "        self.fy = 320.0  # focal length y\n",
    "        self.cx = 320.0  # optical center x\n",
    "        self.cy = 240.0  # optical center y\n",
    "\n",
    "        self.fov = 90 #deg # field of view\n",
    "\n",
    "        self.width = 640\n",
    "        self.height = 480\n",
    "        \n",
    "        path = repo_path + '/' + scene_name + '/' \n",
    "        path += scene_name +'/' + difficulty + '/' + \"P\" + str(part_id).zfill(3) + '/'\n",
    "        self.left_images = load_images_from_directory(path + 'image_left')\n",
    "        self.right_images = load_images_from_directory(path + 'image_right')\n",
    "        self.left_depth = load_depth_data_from_directory(path + 'depth_left')\n",
    "        self.right_depth = load_depth_data_from_directory(path + 'depth_right')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ec491e3-724c-446b-baf3-0e4225d50ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workspace/TartanAir/carwelding/carwelding/Easy/P001/image_left'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28468/1137730828.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtartan_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTartanData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/workspace/TartanAir\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"carwelding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_28468/2977629.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, repo_path, scene_name, part_id, difficulty)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepo_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscene_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mscene_name\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdifficulty\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"P\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'image_left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'image_right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_depth_data_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'depth_left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_28468/2977629.py\u001b[0m in \u001b[0;36mload_images_from_directory\u001b[0;34m(directory_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_images_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Get all files from the directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mall_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Filter out non-image files if necessary (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/workspace/TartanAir/carwelding/carwelding/Easy/P001/image_left'"
     ]
    }
   ],
   "source": [
    "tartan_data = TartanData(\"/workspace/TartanAir\", \"carwelding\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19845046-ad3a-48a4-8209-74d47d907bc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tartan_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28468/1965163330.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mleft_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtartan_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mright_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtartan_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mleft_depths_GT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtartan_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mright_depths_GT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtartan_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tartan_data' is not defined"
     ]
    }
   ],
   "source": [
    "left_images = tartan_data.left_images\n",
    "right_images = tartan_data.right_images\n",
    "left_depths_GT = tartan_data.left_depth\n",
    "right_depths_GT = tartan_data.right_depth\n",
    "\n",
    "\n",
    "print(right_images.shape)\n",
    "print(left_images.shape)\n",
    "print(left_depths_GT.shape)\n",
    "print(right_depths_GT.shape)\n",
    "\n",
    "normalize = lambda img: (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "idx = 200\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
    "axes[0, 0].imshow(left_images[idx])\n",
    "axes[0, 1].imshow(right_images[idx])\n",
    "axes[1, 0].imshow(normalize(left_depths_GT[idx]), cmap='gray')\n",
    "axes[1, 1].imshow(normalize(right_depths_GT[idx]), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9506c8-bab0-47ec-87e6-2e6ea98b14bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'left_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28468/3546803264.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTTR_input_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'left_images' is not defined"
     ]
    }
   ],
   "source": [
    "idx = 200\n",
    "input_data = STTR_input_factory(left_images[idx], right_images[idx])\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_data)\n",
    "    \n",
    "disp_map = output['disp_pred'].data.cpu().numpy()[0]\n",
    "occ_map = output['occ_pred'].data.cpu().numpy()[0] > 0.5\n",
    "disp_map[occ_map] = 0.0\n",
    "\n",
    "# culling\n",
    "disp_map = disp_map[:350, 100:1100]\n",
    "\n",
    "# points_3D = disparity_to_3D_points(left_prj, right_prj, disp_map)\n",
    "\n",
    "# # Mask out points where disparity is 0 (or less) as they're likely invalid\n",
    "# mask = disp_map > 0\n",
    "# valid_points_3D = points_3D[mask]\n",
    "\n",
    "print(valid_points_3D.shape)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.imshow(left_images[idx])\n",
    "plt.figure(2)\n",
    "plt.imshow(disp_map)\n",
    "plt.show()\n",
    "\n",
    "# visualize_3D_points_in_jupyter(valid_points_3D, size=1, marker='sphere')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e56a64a-682c-4c1f-a132-90e06468fed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa2507-b24b-4155-bf76-d2966ad7a743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
